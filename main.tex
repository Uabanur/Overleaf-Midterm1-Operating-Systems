\documentclass{article}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\title{Midterm1 - Operating Systems}
\author{Roar Nind Steffensen\\s144107}
\date{October 2017}

\begin{document}

\maketitle

In order not to repeat the text from the given assignment, it is assumed that the reader knows the content of the following problems as given in the assignment\cite{assignment}.
\section{Problem 1: Working with pointers}
\subsection{Question 1.1 (8 p)}

Using the given struct \texttt{struct data} and the sample data, a bubble sort is implemented. The array containing pointers to structs, is iterated through $n-1$ times, with $n$ being the size of the array. In order to remove redundant checks, after each iteration through the array, the last checked element is not checked for future iterations (we know it has its final position). This results in $\frac{n(n-1)}{2}$ checks instead of $(n-1)^2$. The source code is seen in the attached \texttt{BubbleSort.c} file.

The swapping of elements, is done using a function called \texttt{swap} using the array of struct pointers and the two indexes as parameters. In this case, one index would be sufficient, since only neighbors are swapped. The information being swapped, is only what the pointers in \texttt{array} point to, meaning no structs are moved in memory, only the pointers who reference them.

Running the program in the VirtualBox image given in the course, we get the expected \texttt{\{0 43 37 11 73 53\}} sorting from the sample data.

\section{Problem 2: Debugging}
\subsection{Question 2.1 (5 p)}

Inspecting the code from \texttt{debug.c} we see that malloc is used to allocate memory for an array \texttt{a} of 10 integers. When the array is filled, we see, that we go beyond the bounds of the array in the loop, since the array index 10 is set. C would not complain, but the behavior of the last assignment is unknown. The assignment of the integers in \texttt{a}, is to the return values of \texttt{getchar()}. To be certain, we could set a cast to an integer, although this should not cause problems. 

It is also noted, that the input is not checked for \texttt{"\textbackslash n"} meaning that unwanted assignment may occur to intermediate newline input, it is not certain if this behavior is wanted. Also since the input characters are cast/interpreted as integers, the printed values are the corresponding ASCII values. Since it is not clear if the characters or ASCII values are to be printed, this is not changed. 

Running the file, we see that we indeed get prompted twice for a key press since the newline character is caught by \texttt{getchar()}. From the prompt message, we expect that the characters should be inputted on their respective lines, ignoring newline characters, these are therefore flushed in a \texttt{while((c = getchar()) == '\textbackslash n');} while loop. The for loops are set to iterate from \texttt{i = 0} to \texttt{i < ARRAYSIZE} ensuring that the elements accessed are within the allocated memory of \texttt{a}. The resulting program/source code is seen in the attached \texttt{debugCorrected.c} file.

\section{Problem 3: Various questions}
\subsection{Question 3.1 (1 p)}

The answer to this question depends a lot on what kind of algorithms/programs are run, what architecture is used (e.g. use of pipelining), and what caching strategy is being executed. For these reasons, the rough estimations of Tanenbaum\cite{tanenbaum} section 1.3 figure 1-9 is referenced. 

This is a very rough estimate, since it does not considerate L1, L2 and L3 seperately, but given the little information we know about the actual problem, this seems like a fair approximation.

From the referenced figure, we see (assuming registers are accessed in 1 clock cycle) that cache takes about twice the time of a clock cycle to access, while main memory takes about 10 times the time to access. For a program, which is written to use cache, we might expect that 80\% of the memory operations are cache hit's while the remaining 20\% are cache misses. This would result in an average time of $0.8\cdot2 + 0.2\cdot10 = 3.6$ times the time of a clock cycle.

The total overhead time for a cache miss is calculated as the total search time $T_s$ and the eviction time $T_e$ of old cache, for all levels. Since all cache misses results in memory being stored from the lowest reached memory level to all levels above, each miss creates more and more severe time penalties. These should all be taken into consideration if an more accurate estimation of memory access time is to be calculated.



\subsection{Question 3.2 (2 p)}
The main reason for using cache, is that cpu speeds outperform memory access time, meaning that the majority of the CPU time would be in idle, waiting for the bus from main memory. Cache is used in order to gain local memory access without the use of the bus, to get faster memory retrieval. This means that the CPU is used more efficiently. 


\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
